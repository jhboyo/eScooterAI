"""
YOLOv8 ëª¨ë¸ ì¶”ë¡  ìœ í‹¸ë¦¬í‹°
Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•œ PPE íƒì§€ ì¶”ë¡  ê¸°ëŠ¥

Author: Safety Vision AI Team
Date: 2025-11-22
"""

import streamlit as st
from ultralytics import YOLO
from pathlib import Path
import time
from typing import List, Dict, Optional
import numpy as np
from PIL import Image


# ============================================================================
# ëª¨ë¸ ë¡œë“œ (ìºì‹±)
# ============================================================================

@st.cache_resource
def load_model(model_path: str) -> Optional[YOLO]:
    """
    YOLOv8 ëª¨ë¸ ë¡œë“œ (ì„¸ì…˜ ê°„ ìºì‹±)

    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: "models/ppe_detection/weights/best.pt")

    Returns:
        YOLO: ë¡œë“œëœ YOLOv8 ëª¨ë¸ ê°ì²´
        None: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ

    Note:
        @st.cache_resource ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ê³ 
        ì„¸ì…˜ ê°„ì— ê³µìœ í•©ë‹ˆë‹¤. ì´ëŠ” ì„±ëŠ¥ í–¥ìƒì— ì¤‘ìš”í•©ë‹ˆë‹¤.
    """
    try:
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
        model_file = Path(model_path)

        if not model_file.exists():
            st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

            # ë””ë²„ê¹… ì •ë³´
            import os
            with st.expander("ğŸ” ë””ë²„ê¹… ì •ë³´"):
                st.code(f"""
í˜„ì¬ íŒŒì¼: {Path(__file__).resolve()}
ëª¨ë¸ ê²½ë¡œ: {model_file}
íŒŒì¼ ì¡´ì¬: {model_file.exists()}
ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}
ë””ë ‰í† ë¦¬ ë‚´ìš©:
{chr(10).join([f"  - {p}" for p in Path('.').glob('**/*') if p.is_file()][:20])}
                """)

            st.info("ğŸ’¡ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ í•™ìŠµì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”:\n```bash\nuv run python src/training/train.py\n```")
            return None

        # Git LFS í¬ì¸í„° íŒŒì¼ ê²€ì¦
        with open(model_file, 'rb') as f:
            first_bytes = f.read(100)
            # LFS í¬ì¸í„° íŒŒì¼ì€ "version https://git-lfs.github.com/spec/v1"ë¡œ ì‹œì‘
            if first_bytes.startswith(b'version https://git-lfs'):
                st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì´ Git LFS í¬ì¸í„°ì…ë‹ˆë‹¤!")
                st.error("Streamlit CloudëŠ” Git LFSë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                with st.expander("ğŸ” LFS í¬ì¸í„° ë‚´ìš©"):
                    st.code(first_bytes.decode('utf-8', errors='ignore'))
                st.info("""
                **í•´ê²° ë°©ë²•:**
                1. ë¡œì»¬ì—ì„œ ëª¨ë¸ì„ Hugging Face Hubì— ì—…ë¡œë“œ
                2. ì•± ì‹œì‘ ì‹œ HF Hubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
                3. ë˜ëŠ” GitHubì—ì„œ LFS ì™„ì „íˆ ì œê±° í›„ ì¬ë°°í¬
                """)
                return None
            # PyTorch ëª¨ë¸ì€ ZIP íŒŒì¼ (PKë¡œ ì‹œì‘)
            elif not first_bytes.startswith(b'PK'):
                st.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")
                with st.expander("ğŸ” íŒŒì¼ í—¤ë”"):
                    st.code(f"First 50 bytes: {first_bytes[:50]}")

        # ëª¨ë¸ ë¡œë“œ (ìŠ¤í”¼ë„ˆ í‘œì‹œ)
        with st.spinner(f"ğŸ”„ YOLOv8 ëª¨ë¸ ë¡œë”© ì¤‘... ({model_file.name})"):
            model = YOLO(str(model_file))

        st.success(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file.name}")

        # ëª¨ë¸ ì •ë³´ ì¶œë ¥ (ë””ë²„ê·¸ìš©)
        class_list = ', '.join([f"{k}: {v}" for k, v in model.names.items()])
        st.sidebar.info(f"""
        **ëª¨ë¸ ì •ë³´**
        - íŒŒì¼: {model_file.name}
        - í´ë˜ìŠ¤ ìˆ˜: {len(model.names)}ê°œ
        - í´ë˜ìŠ¤ ëª©ë¡: {class_list}
        - ì¥ì¹˜: {'GPU (CUDA)' if model.device.type == 'cuda' else 'CPU'}
        """)

        # í´ë˜ìŠ¤ í™•ì¸ìš© ê²½ê³  ë©”ì‹œì§€
        expected_classes = {'helmet', 'head', 'vest'}
        actual_classes = set(model.names.values())
        if not expected_classes.issubset(actual_classes):
            missing = expected_classes - actual_classes
            st.sidebar.warning(f"âš ï¸ ì˜ˆìƒ í´ë˜ìŠ¤ ëˆ„ë½: {missing}")

        return model

    except Exception as e:
        st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.exception(e)
        return None


# ============================================================================
# ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
# ============================================================================

def run_inference_single(
    model: YOLO,
    image: Image.Image,
    conf: float = 0.25,
    iou: float = 0.45,
    max_det: int = 300,
    debug: bool = False
) -> Dict:
    """
    ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ PPE íƒì§€ ì¶”ë¡ 

    Args:
        model: YOLOv8 ëª¨ë¸ ê°ì²´
        image: PIL Image ê°ì²´
        conf: ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0 ~ 1.0)
        iou: IoU ì„ê³„ê°’ (Non-Maximum Suppressionìš©)
        max_det: ìµœëŒ€ íƒì§€ ê°ì²´ ìˆ˜
        debug: ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€

    Returns:
        Dict: ì¶”ë¡  ê²°ê³¼
            - detections: íƒì§€ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸
            - image_shape: ì´ë¯¸ì§€ í¬ê¸° (width, height)
            - inference_time: ì¶”ë¡  ì‹œê°„ (ì´ˆ)
            - num_detections: íƒì§€ëœ ê°ì²´ ìˆ˜
            - debug_info: ë””ë²„ê·¸ ì •ë³´ (debug=Trueì¼ ë•Œ)
    """
    try:
        # YOLOv8 ì¶”ë¡  ì‹¤í–‰
        results = model(
            image,
            conf=conf,
            iou=iou,
            max_det=max_det,
            verbose=False  # ì½˜ì†” ì¶œë ¥ ì–µì œ
        )[0]

        # ê²°ê³¼ íŒŒì‹±
        boxes = results.boxes
        detections = []
        debug_info = {
            'total_boxes': len(boxes) if boxes is not None else 0,
            'class_distribution': {},
            'all_detections': []  # ëª¨ë“  íƒì§€ ê²°ê³¼ (í•„í„°ë§ ì „)
        }

        if boxes is not None and len(boxes) > 0:
            for box in boxes:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()

                # ì‹ ë¢°ë„ ì ìˆ˜
                conf_score = float(box.conf[0].cpu().numpy())

                # í´ë˜ìŠ¤ ID ë° ì´ë¦„
                cls_id = int(box.cls[0].cpu().numpy())
                cls_name = results.names[cls_id]

                detection = {
                    'bbox': [float(x1), float(y1), float(x2), float(y2)],
                    'confidence': conf_score,
                    'class_id': cls_id,
                    'class_name': cls_name
                }

                detections.append(detection)

                # ë””ë²„ê·¸ ì •ë³´ ìˆ˜ì§‘
                if debug:
                    debug_info['all_detections'].append(detection)
                    if cls_name not in debug_info['class_distribution']:
                        debug_info['class_distribution'][cls_name] = 0
                    debug_info['class_distribution'][cls_name] += 1

        # ì¶”ë¡  ì‹œê°„ (ë°€ë¦¬ì´ˆ â†’ ì´ˆ)
        inference_time = results.speed.get('inference', 0) / 1000

        result = {
            'detections': detections,
            'image_shape': image.size,  # (width, height)
            'inference_time': inference_time,
            'num_detections': len(detections)
        }

        if debug:
            result['debug_info'] = debug_info
            # ì½˜ì†”ì— ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
            print(f"\n=== Debug Info ===")
            print(f"Total detections: {debug_info['total_boxes']}")
            print(f"Class distribution: {debug_info['class_distribution']}")
            for i, det in enumerate(debug_info['all_detections'][:10]):  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                print(f"  [{i+1}] {det['class_name']}: {det['confidence']:.3f}")

        return result

    except Exception as e:
        st.error(f"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {
            'detections': [],
            'image_shape': image.size if hasattr(image, 'size') else (0, 0),
            'inference_time': 0,
            'num_detections': 0,
            'error': str(e)
        }


# ============================================================================
# ë°°ì¹˜ ì´ë¯¸ì§€ ì¶”ë¡  (ì§„í–‰ ìƒíƒœ í‘œì‹œ)
# ============================================================================

def run_inference_batch(
    model: YOLO,
    images: List[Image.Image],
    conf: float = 0.25,
    iou: float = 0.45,
    max_det: int = 300,
    show_progress: bool = True,
    debug: bool = False
) -> List[Dict]:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ë°°ì¹˜ ì¶”ë¡ 

    Args:
        model: YOLOv8 ëª¨ë¸ ê°ì²´
        images: PIL Image ê°ì²´ ë¦¬ìŠ¤íŠ¸
        conf: ì‹ ë¢°ë„ ì„ê³„ê°’
        iou: IoU ì„ê³„ê°’
        max_det: ìµœëŒ€ íƒì§€ ê°ì²´ ìˆ˜
        show_progress: ì§„í–‰ ìƒíƒœ í‘œì‹œ ì—¬ë¶€
        debug: ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€

    Returns:
        List[Dict]: ê° ì´ë¯¸ì§€ì˜ ì¶”ë¡  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    results = []
    total_images = len(images)

    # ì§„í–‰ ìƒíƒœ í‘œì‹œ
    if show_progress:
        progress_bar = st.progress(0)
        status_text = st.empty()

    # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì¶”ë¡  ì‹¤í–‰
    for idx, image in enumerate(images):
        # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        if show_progress:
            progress = (idx + 1) / total_images
            progress_bar.progress(progress)
            status_text.text(f"ğŸ” ì¶”ë¡  ì¤‘... ({idx + 1}/{total_images})")

        # ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
        result = run_inference_single(model, image, conf, iou, max_det, debug=debug)
        result['image_index'] = idx
        results.append(result)

    # ì§„í–‰ ìƒíƒœ í‘œì‹œ ì™„ë£Œ
    if show_progress:
        progress_bar.progress(1.0)
        status_text.text(f"âœ… ì¶”ë¡  ì™„ë£Œ! ({total_images}/{total_images})")
        # ì ì‹œ í›„ ìƒíƒœ ë©”ì‹œì§€ ì œê±°
        import time
        time.sleep(0.5)
        progress_bar.empty()
        status_text.empty()

    return results


# ============================================================================
# ì¶”ë¡  ê²°ê³¼ ìš”ì•½ í†µê³„
# ============================================================================

def summarize_results(results: List[Dict]) -> Dict:
    """
    ë°°ì¹˜ ì¶”ë¡  ê²°ê³¼ì˜ ìš”ì•½ í†µê³„ ê³„ì‚°

    Args:
        results: run_inference_batch()ì˜ ë°˜í™˜ê°’

    Returns:
        Dict: ìš”ì•½ í†µê³„
            - total_images: ì´ ì´ë¯¸ì§€ ìˆ˜
            - total_detections: ì´ íƒì§€ ê°ì²´ ìˆ˜
            - avg_detections_per_image: ì´ë¯¸ì§€ë‹¹ í‰ê·  íƒì§€ ìˆ˜
            - class_counts: í´ë˜ìŠ¤ë³„ íƒì§€ ìˆ˜
    """
    total_detections = 0
    class_counts = {}

    for result in results:
        total_detections += result['num_detections']

        for det in result['detections']:
            cls_name = det['class_name']
            class_counts[cls_name] = class_counts.get(cls_name, 0) + 1

    return {
        'total_images': len(results),
        'total_detections': total_detections,
        'avg_detections_per_image': total_detections / len(results) if results else 0,
        'class_counts': class_counts
    }


# ============================================================================
# ëª¨ë¸ ê²½ë¡œ í—¬í¼ í•¨ìˆ˜
# ============================================================================

def get_model_path(model_name: str) -> Path:
    """
    ëª¨ë¸ ì´ë¦„ìœ¼ë¡œë¶€í„° ì „ì²´ ê²½ë¡œ ë°˜í™˜

    Args:
        model_name: 'best.pt' ë˜ëŠ” 'last.pt'

    Returns:
        Path: ëª¨ë¸ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ
    """
    import os

    # í˜„ì¬ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ
    current_file = Path(__file__).resolve()

    # Streamlit Cloud í™˜ê²½ ê°ì§€ (/mount/src/<repo-name>/)
    is_streamlit_cloud = str(current_file).startswith('/mount/src/')

    # Hugging Face Spaces í™˜ê²½ ê°ì§€
    is_hf_spaces = os.environ.get("SPACE_ID") is not None

    # í™˜ê²½ë³„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
    if is_streamlit_cloud:
        # Streamlit Cloud: /mount/src/safetyvisionai/src/web_interface/utils/inference.py
        # -> /mount/src/safetyvisionai/
        project_root = current_file.parent.parent.parent.parent
    elif is_hf_spaces:
        # HF Spaces: app.pyì™€ ê°™ì€ ë ˆë²¨ì— utilsê°€ ìˆìŒ
        # <root>/utils/inference.py -> <root>/
        project_root = current_file.parent.parent
    else:
        # ë¡œì»¬ ê°œë°œ: SafetyVisionAI/src/web_interface/utils/inference.py
        # -> SafetyVisionAI/
        project_root = current_file.parent.parent.parent.parent

    model_path = project_root / "models" / "ppe_detection" / "weights" / model_name

    # ë””ë²„ê¹… ì •ë³´ (íŒŒì¼ì´ ì—†ì„ ê²½ìš°ì—ë§Œ ì¶œë ¥)
    if not model_path.exists():
        print(f"[DEBUG] Model path not found: {model_path}")
        print(f"[DEBUG] Current file: {current_file}")
        print(f"[DEBUG] Project root: {project_root}")
        print(f"[DEBUG] Is Streamlit Cloud: {is_streamlit_cloud}")
        print(f"[DEBUG] Is HF Spaces: {is_hf_spaces}")

        # ìƒìœ„ ë””ë ‰í† ë¦¬ íƒìƒ‰ìœ¼ë¡œ í´ë°±
        for level in range(2, 6):
            potential_root = current_file
            for _ in range(level):
                potential_root = potential_root.parent
            potential_path = potential_root / "models" / "ppe_detection" / "weights" / model_name
            print(f"[DEBUG] Trying level {level}: {potential_path}")
            if potential_path.exists():
                print(f"[DEBUG] Found at level {level}!")
                return potential_path

    return model_path
