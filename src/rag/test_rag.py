"""
RAG System Testing and Evaluation

RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ë° í…ŒìŠ¤íŠ¸
- Precision@K: Top-K ê²€ìƒ‰ ì •í™•ë„
- Answer Relevance: ë‹µë³€ ê´€ë ¨ì„±
- Response Time: ì‘ë‹µ ì‹œê°„
- Hallucination Check: í™˜ê° í˜„ìƒ ê²€ì¦
"""

import os
import sys
import time
from pathlib import Path
from typing import List, Dict, Tuple
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.rag.vector_store import FAISSVectorStore
from src.rag.query_engine import RAGQueryEngine


class RAGTester:
    """
    RAG ì‹œìŠ¤í…œ í…ŒìŠ¤í„°

    ë‹¤ì–‘í•œ ì§ˆë¬¸ ìœ í˜•ìœ¼ë¡œ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€
    """

    def __init__(self, vector_store: FAISSVectorStore, query_engine: RAGQueryEngine):
        """
        RAG í…ŒìŠ¤í„° ì´ˆê¸°í™”

        Args:
            vector_store: FAISS ë²¡í„° ì €ì¥ì†Œ
            query_engine: RAG ì¿¼ë¦¬ ì—”ì§„
        """
        self.vector_store = vector_store
        self.query_engine = query_engine

    def test_retrieval_precision(
        self,
        test_cases: List[Tuple[str, str]]
    ) -> Dict[str, any]:
        """
        ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸ (Precision@K)

        Args:
            test_cases: (query, expected_category) ìŒì˜ ë¦¬ìŠ¤íŠ¸

        Returns:
            Dict: í‰ê°€ ê²°ê³¼
        """
        print("\n" + "="*80)
        print("ğŸ“Š Retrieval Precision@K Test")
        print("="*80 + "\n")

        # ========================================================================
        # Precision@K í‰ê°€
        # ========================================================================
        # ì •ë³´ ê²€ìƒ‰(IR) ë¶„ì•¼ì˜ ëŒ€í‘œì ì¸ í‰ê°€ ì§€í‘œ
        # - Kê°œì˜ ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ê´€ë ¨ ë¬¸ì„œê°€ í¬í•¨ëœ ë¹„ìœ¨
        # - Formula: Precision@K = (ê´€ë ¨ ë¬¸ì„œ ìˆ˜) / K
        # - ë³¸ í…ŒìŠ¤íŠ¸: Top-3 ì¤‘ í•˜ë‚˜ë¼ë„ ì˜¬ë°”ë¥¸ ì¹´í…Œê³ ë¦¬ë©´ ì •ë‹µ (Recall@3)
        #
        # ì˜ˆì‹œ:
        # - Query: "í—¬ë©§ ì•ˆ ì“°ë©´ ë²Œê¸ˆ?"
        # - Expected: "ë²•ê·œ" ì¹´í…Œê³ ë¦¬
        # - Top-3 ê²°ê³¼: ["ë²•ê·œ", "ê°€ì´ë“œ", "ì‚¬ë¡€"]
        # - Hit: True (ë²•ê·œ í¬í•¨ë¨)
        total = len(test_cases)
        correct = 0
        results = []

        for query, expected_category in test_cases:
            # FAISS ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰ (Top-3)
            search_results = self.vector_store.search(query, top_k=3)

            # Top-3 ì¤‘ í•˜ë‚˜ë¼ë„ expected_categoryì™€ ì¼ì¹˜í•˜ë©´ ì •ë‹µ
            # any(): ë¦¬ìŠ¤íŠ¸ì—ì„œ í•˜ë‚˜ë¼ë„ Trueë©´ True ë°˜í™˜
            hit = any(
                doc["metadata"].get("category") == expected_category
                for doc in search_results
            )

            if hit:
                correct += 1  # ì •ë‹µ ì¹´ìš´íŠ¸ ì¦ê°€

            results.append({
                "query": query,
                "expected_category": expected_category,
                "retrieved_categories": [
                    doc["metadata"].get("category", "N/A")
                    for doc in search_results
                ],
                "hit": hit
            })

            status = "âœ…" if hit else "âŒ"
            print(f"{status} Query: {query}")
            print(f"   Expected: {expected_category}")
            print(f"   Retrieved: {[doc['metadata'].get('category') for doc in search_results]}")

        precision = correct / total if total > 0 else 0

        print(f"\nğŸ“ˆ Precision@3: {precision:.2%} ({correct}/{total})")

        return {
            "precision": precision,
            "correct": correct,
            "total": total,
            "results": results
        }

    def test_answer_quality(
        self,
        test_questions: List[str]
    ) -> Dict[str, any]:
        """
        ë‹µë³€ í’ˆì§ˆ í…ŒìŠ¤íŠ¸

        Args:
            test_questions: í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            Dict: í‰ê°€ ê²°ê³¼
        """
        print("\n" + "="*80)
        print("ğŸ’¬ Answer Quality Test")
        print("="*80 + "\n")

        # ========================================================================
        # ë‹µë³€ í’ˆì§ˆ í‰ê°€
        # ========================================================================
        # RAG ì‹œìŠ¤í…œì˜ ì¢…ë‹¨ê°„(End-to-End) ì„±ëŠ¥ í‰ê°€
        # ì¸¡ì • ì§€í‘œ:
        # 1. Response Time: ë‹µë³€ ìƒì„± ì†ë„ (ì´ˆ)
        #    - Retrieval + LLM í˜¸ì¶œ í¬í•¨
        # 2. Token Usage: OpenAI API í† í° ì‚¬ìš©ëŸ‰
        #    - ë¹„ìš© ì¶”ì • ë° ìµœì í™”ì— í™œìš©
        # 3. Answer Relevance: ë‹µë³€ ê´€ë ¨ì„± (ìˆ˜ë™ í‰ê°€ í•„ìš”)
        #
        # ìë™í™”ëœ í‰ê°€ë¥¼ ìœ„í•´ì„œëŠ”:
        # - GPT-4 as Judge: LLMìœ¼ë¡œ ë‹µë³€ í’ˆì§ˆ í‰ê°€
        # - BLEU/ROUGE: ì°¸ì¡° ë‹µë³€ê³¼ ë¹„êµ
        # - Semantic Similarity: ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        results = []
        total_time = 0
        total_tokens = 0

        for i, question in enumerate(test_questions, 1):
            print(f"\n[{i}/{len(test_questions)}] Question: {question}")

            # ì‹œê°„ ì¸¡ì • ì‹œì‘ (Retrieval + Generation ì „ì²´ ì‹œê°„)
            start_time = time.time()
            result = self.query_engine.query(question, return_sources=True)
            elapsed_time = time.time() - start_time

            # ëˆ„ì  í†µê³„ ì—…ë°ì´íŠ¸
            total_time += elapsed_time
            total_tokens += result["metadata"]["total_tokens"]

            print(f"   Answer: {result['answer']}")
            print(f"   Response Time: {elapsed_time:.2f}s")
            print(f"   Tokens Used: {result['metadata']['total_tokens']}")
            print(f"   Sources: {result['metadata']['num_sources']}")

            results.append({
                "question": question,
                "answer": result["answer"],
                "response_time": elapsed_time,
                "tokens": result["metadata"]["total_tokens"],
                "num_sources": result["metadata"]["num_sources"],
                "sources": result.get("sources", [])
            })

        avg_time = total_time / len(test_questions) if test_questions else 0
        avg_tokens = total_tokens / len(test_questions) if test_questions else 0

        print(f"\nğŸ“ˆ Average Response Time: {avg_time:.2f}s")
        print(f"ğŸ“ˆ Average Tokens Used: {avg_tokens:.1f}")

        return {
            "results": results,
            "avg_response_time": avg_time,
            "avg_tokens": avg_tokens,
            "total_questions": len(test_questions)
        }

    def test_edge_cases(self) -> Dict[str, any]:
        """
        ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸

        - ì—†ëŠ” ì •ë³´ ì§ˆë¬¸ (Hallucination ì²´í¬)
        - ëª¨í˜¸í•œ ì§ˆë¬¸
        - ë³µí•© ì§ˆë¬¸

        Returns:
            Dict: í‰ê°€ ê²°ê³¼
        """
        print("\n" + "="*80)
        print("ğŸ§ª Edge Cases Test")
        print("="*80 + "\n")

        # ========================================================================
        # ì—£ì§€ ì¼€ì´ìŠ¤ í‰ê°€
        # ========================================================================
        # RAG ì‹œìŠ¤í…œì˜ ê²¬ê³ ì„±(Robustness) ê²€ì¦
        #
        # 1. Hallucination Check (í™˜ê° í˜„ìƒ ê²€ì¦)
        #    - ì§€ì‹ ë² ì´ìŠ¤ì— ì—†ëŠ” ì •ë³´ë¥¼ ë¬¼ì–´ë´„
        #    - "ëª¨ë¥´ê² ë‹¤"ê³  ë‹µë³€í•´ì•¼ í•¨ (ê±°ì§“ ì •ë³´ ìƒì„± ë°©ì§€)
        #    - ì¤‘ìš”: ì˜ë£Œ/ë²•ë¥  ë¶„ì•¼ì—ì„œ ì¹˜ëª…ì 
        #
        # 2. Ambiguous Queries (ëª¨í˜¸í•œ ì§ˆë¬¸)
        #    - ë¶ˆì™„ì „í•˜ê±°ë‚˜ ì• ë§¤í•œ ì§ˆë¬¸ ì²˜ë¦¬ ëŠ¥ë ¥
        #    - ì¼ë°˜ì ì¸ ì•ˆì „ ìˆ˜ì¹™ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•¨
        #
        # 3. Complex Queries (ë³µí•© ì§ˆë¬¸)
        #    - ì—¬ëŸ¬ ê°œë…ì„ ê²°í•©í•œ ì§ˆë¬¸
        #    - ë‹¤ì¤‘ ë¬¸ì„œ ì°¸ì¡° ë° ì¶”ë¡  ëŠ¥ë ¥ í‰ê°€
        edge_cases = [
            {
                "type": "missing_info",  # í™˜ê° ë°©ì§€ í…ŒìŠ¤íŠ¸
                "question": "ì „ë™í‚¥ë³´ë“œ ë³´í—˜ë£ŒëŠ” ì–¼ë§ˆì•¼?",
                "expected_behavior": "ì œê³µëœ ìë£Œì— ì—†ë‹¤ê³  ë‹µë³€"
            },
            {
                "type": "ambiguous",  # ëª¨í˜¸í•œ ì§ˆë¬¸ ì²˜ë¦¬
                "question": "ì•ˆì „í•˜ê²Œ íƒ€ë ¤ë©´?",
                "expected_behavior": "í—¬ë©§ ì°©ìš© ë° ì•ˆì „ ìˆ˜ì¹™ ì•ˆë‚´"
            },
            {
                "type": "complex",  # ë³µí•© ì¶”ë¡  í…ŒìŠ¤íŠ¸
                "question": "í—¬ë©§ ì•ˆ ì“°ê³  ì¸ë„ë¡œ ë‹¬ë¦¬ë©´ ë²Œê¸ˆ ì–¼ë§ˆì•¼?",
                "expected_behavior": "í—¬ë©§ ë¯¸ì°©ìš©(2ë§Œì›) + ì¸ë„ ì£¼í–‰(4ë§Œì›) = 6ë§Œì›"
            }
        ]

        results = []

        for case in edge_cases:
            print(f"\nğŸ” Type: {case['type']}")
            print(f"   Question: {case['question']}")
            print(f"   Expected: {case['expected_behavior']}")

            result = self.query_engine.query(case["question"])
            print(f"   Answer: {result['answer']}")

            results.append({
                **case,
                "answer": result["answer"],
                "metadata": result["metadata"]
            })

        return {"results": results}


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    load_dotenv()

    print("\n" + "="*80)
    print("ğŸ§ª RAG System Comprehensive Testing")
    print("="*80)

    # 1. ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
    print("\nğŸ“‚ Loading vector store...")
    vector_store = FAISSVectorStore()

    try:
        vector_store.load(os.getenv("VECTOR_DB_PATH", "./vector_db"))
        print(f"âœ… Vector store loaded: {vector_store.get_stats()}")
    except FileNotFoundError:
        print("âŒ Vector database not found.")
        print("   Please run 'uv run python src/rag/build_vector_db.py' first")
        return

    # 2. ì¿¼ë¦¬ ì—”ì§„ ì´ˆê¸°í™”
    print("\nğŸ¤– Initializing RAG query engine...")
    query_engine = RAGQueryEngine(
        vector_store=vector_store,
        model=os.getenv("RAG_LLM_MODEL", "gpt-4-turbo-preview"),
        temperature=float(os.getenv("RAG_TEMPERATURE", "0.3")),
        max_tokens=int(os.getenv("RAG_MAX_TOKENS", "500")),
        top_k=int(os.getenv("RAG_TOP_K", "3"))
    )

    print(f"âœ… RAG engine ready: {query_engine.get_stats()}")

    # 3. í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = RAGTester(vector_store, query_engine)

    # 4. Precision@K í…ŒìŠ¤íŠ¸
    precision_test_cases = [
        ("í—¬ë©§ ì•ˆ ì“°ë©´ ë²Œê¸ˆ?", "ë²•ê·œ"),
        ("í—¬ë©§ ì°©ìš©ë²•", "ê°€ì´ë“œ"),
        ("ì „ë™í‚¥ë³´ë“œ ì‚¬ê³  ì‚¬ë¡€", "ì‚¬ë¡€"),
        ("ìŒì£¼ìš´ì „ ì²˜ë²Œ", "ë²•ê·œ"),
        ("ì•¼ê°„ ìš´í–‰ ì£¼ì˜ì‚¬í•­", "ê°€ì´ë“œ"),
        ("í—¬ë©§ ì°©ìš©ë¥ ", "ì‚¬ë¡€"),
        ("ì¸ë„ ì£¼í–‰ ê¸ˆì§€", "ë²•ê·œ"),
        ("ë°°í„°ë¦¬ ê´€ë¦¬", "ê°€ì´ë“œ"),
        ("2ì¸ íƒ‘ìŠ¹ ì‚¬ê³ ", "ì‚¬ë¡€")
    ]

    precision_results = tester.test_retrieval_precision(precision_test_cases)

    # 5. ë‹µë³€ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
    quality_test_questions = [
        "í—¬ë©§ ì•ˆ ì“°ë©´ ë²Œê¸ˆ ì–¼ë§ˆì•¼?",
        "í—¬ë©§ ì˜¬ë°”ë¥´ê²Œ ì°©ìš©í•˜ëŠ” ë°©ë²• ì•Œë ¤ì¤˜",
        "ì „ë™í‚¥ë³´ë“œ ìŒì£¼ìš´ì „í•˜ë©´ ì–´ë–»ê²Œ ë¼?",
        "ì•¼ê°„ì— ì „ë™í‚¥ë³´ë“œ íƒ€ë ¤ë©´ ë­˜ ì¼œì•¼ í•´?",
        "í—¬ë©§ ì°©ìš©í•˜ë©´ ì‚¬ê³  ìœ„í—˜ì´ ì–¼ë§ˆë‚˜ ì¤„ì–´ë“¤ì–´?",
        "ì „ë™í‚¥ë³´ë“œ ì¸ë„ë¡œ íƒ€ë©´ ì•ˆ ë˜ëŠ” ì´ìœ ?",
    ]

    quality_results = tester.test_answer_quality(quality_test_questions)

    # 6. ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
    edge_results = tester.test_edge_cases()

    # 7. ìµœì¢… ìš”ì•½
    print("\n" + "="*80)
    print("ğŸ“Š Final Evaluation Summary")
    print("="*80)

    print(f"\n1ï¸âƒ£  Retrieval Performance:")
    print(f"   - Precision@3: {precision_results['precision']:.2%}")
    print(f"   - Correct Retrievals: {precision_results['correct']}/{precision_results['total']}")

    print(f"\n2ï¸âƒ£  Answer Generation Performance:")
    print(f"   - Average Response Time: {quality_results['avg_response_time']:.2f}s")
    print(f"   - Average Tokens: {quality_results['avg_tokens']:.1f}")
    print(f"   - Total Questions Tested: {quality_results['total_questions']}")

    print(f"\n3ï¸âƒ£  Edge Cases:")
    print(f"   - Total Edge Cases Tested: {len(edge_results['results'])}")

    # ë¹„ìš© ì¶”ì • (OpenAI Pricing ê¸°ì¤€)
    total_tokens = quality_results['avg_tokens'] * quality_results['total_questions']
    embedding_cost = vector_store.get_stats()['total_documents'] * 0.00002 / 1000  # text-embedding-3-small
    generation_cost = total_tokens * 0.00003 / 1000  # gpt-4-turbo rough estimate

    print(f"\nğŸ’° Estimated Cost:")
    print(f"   - Embedding Cost: ${embedding_cost:.4f}")
    print(f"   - Generation Cost: ${generation_cost:.4f}")
    print(f"   - Total: ${embedding_cost + generation_cost:.4f}")

    print("\nâœ… Testing completed successfully!")


if __name__ == "__main__":
    main()
