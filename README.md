# Safety Vision AI - ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê±´ì„¤í˜„ì¥ ì•ˆì „ ì¥ë¹„ ì°©ìš© ëª¨ë‹ˆí„°ë§ í”Œë«í¼

ë”¥ëŸ¬ë‹ ê¸°ë°˜ì˜ ì‘ì—…ì ê°œì¸ë³´í˜¸êµ¬(PPE) ì°©ìš© ê°ì§€ ë° ì‚°ì—…ì•ˆì „ ì¬í•´ ë°©ì§€ë¥¼ ìœ„í•œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ í”„ë¡œì íŠ¸

## ğŸ“‹ í”„ë¡œì íŠ¸ ì§„í–‰ ìˆœì„œ

### Phase 1: í™˜ê²½ ì„¤ì • âœ… ì™„ë£Œ
- [x] Python ê°€ìƒí™˜ê²½ ìƒì„± (uv)
- [x] TensorFlow, OpenCV, Jupyter ë“± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
- [x] í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ìƒì„±

### Phase 2: ë°ì´í„°ì…‹ ì¤€ë¹„ ğŸ”„ ì§„í–‰ ì¤‘
1. **ë°ì´í„°ì…‹ ìˆ˜ì§‘** âœ… ì™„ë£Œ
   - [x] Hard Hat Detection (Kaggle) ë‹¤ìš´ë¡œë“œ
   - [x] Safety Helmet and Reflective Jacket (Kaggle) ë‹¤ìš´ë¡œë“œ

2. **ë°ì´í„° ì „ì²˜ë¦¬** â³ ëŒ€ê¸°
   - [ ] ë¼ë²¨ë§ í¬ë§· í†µì¼ (Pascal VOC XML â†’ YOLO TXT)
   - [ ] í´ë˜ìŠ¤ ID ë§¤í•‘ í†µì¼ (helmet, head/no_helmet, vest ë“±)
   - [ ] ì´ë¯¸ì§€-ë¼ë²¨ íŒŒì¼ ë§¤ì¹­ ê²€ì¦
   - [ ] ì†ìƒëœ íŒŒì¼ ë° ì˜ëª»ëœ ë¼ë²¨ ì œê±°

3. **ë°ì´í„° ë¶„í• ** â³ ëŒ€ê¸°
   - [ ] Train/Val/Test ë¶„í•  (70/15/15)
   - [ ] ë°ì´í„°ì…‹ YAML íŒŒì¼ ì‘ì„± (configs/ppe_dataset.yaml)

4. **ë°ì´í„° ê²€ì¦** â³ ëŒ€ê¸°
   - [ ] ë¼ë²¨ ì‹œê°í™”ë¡œ ì •í™•ì„± í™•ì¸
   - [ ] í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„

### Phase 3: ëª¨ë¸ í›ˆë ¨ â³ ëŒ€ê¸°
1. **ëª¨ë¸ ì„¤ì •**
   - [ ] YOLOv8 ëª¨ë¸ ì„ íƒ (yolov8n ë˜ëŠ” yolov8s)
   - [ ] í›ˆë ¨ ì„¤ì • íŒŒì¼ ì‘ì„± (configs/train_config.yaml)
   - [ ] í´ë˜ìŠ¤ ì •ì˜ (helmet, head, vest)

2. **Transfer Learning**
   - [ ] COCO ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ
   - [ ] PPE ë°ì´í„°ì…‹ìœ¼ë¡œ Fine-tuning (50-100 epochs)
   - [ ] í›ˆë ¨ ì§„í–‰ ëª¨ë‹ˆí„°ë§ (loss, mAP)

3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
   - [ ] í•™ìŠµë¥  ì¡°ì • (0.01, 0.001, 0.0001)
   - [ ] ë°°ì¹˜ í¬ê¸° ì¡°ì • (8, 16, 32)
   - [ ] ë°ì´í„° ì¦ê°• ì„¤ì • (mosaic, flip, hsv ë“±)

### Phase 4: ëª¨ë¸ í‰ê°€ â³ ëŒ€ê¸°
1. **ì„±ëŠ¥ í‰ê°€**
   - [ ] mAP@0.5, mAP@0.5:0.95 ì¸¡ì •
   - [ ] Precision, Recall, F1-Score ê³„ì‚°
   - [ ] í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„
   - [ ] FPS ì¸¡ì • (ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥)

2. **ëª¨ë¸ ê°œì„ **
   - [ ] ì˜¤íƒì§€(False Positive) ë¶„ì„
   - [ ] ë¯¸íƒì§€(False Negative) ë¶„ì„
   - [ ] Confusion Matrix ë¶„ì„
   - [ ] ì¶”ê°€ í›ˆë ¨ ë˜ëŠ” íŒŒë¼ë¯¸í„° ì¡°ì •

### Phase 5: ì¶”ë¡  ì‹œìŠ¤í…œ êµ¬í˜„ â³ ëŒ€ê¸°
1. **ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**
   - [ ] ì´ë¯¸ì§€ ì¶”ë¡  (src/inference.py)
   - [ ] ë¹„ë””ì˜¤ íŒŒì¼ ì¶”ë¡ 
   - [ ] ì›¹ìº  ì‹¤ì‹œê°„ ì¶”ë¡ 

2. **ê²°ê³¼ ì‹œê°í™”**
   - [ ] ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ
   - [ ] í´ë˜ìŠ¤ëª…, ì‹ ë¢°ë„ í‘œì‹œ
   - [ ] ê²°ê³¼ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì €ì¥

### Phase 6: ì›¹ ì¸í„°í˜ì´ìŠ¤ (ì„ íƒ) â³ ëŒ€ê¸°
- [ ] Streamlit ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ êµ¬í˜„
- [ ] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í™”ë©´
- [ ] ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì—…ë¡œë“œ ê¸°ëŠ¥
- [ ] ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„±

---

## ğŸ“Š ë°ì´í„°ì…‹ ë¶„ì„

### Dataset 1: kaggle-safey_helmet (Hard Hat Detection)
| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì´ë¯¸ì§€ ìˆ˜** | 5,000ì¥ |
| **ë¼ë²¨ í˜•ì‹** | Pascal VOC (XML) |
| **ì´ë¯¸ì§€ í˜•ì‹** | PNG (416x416) |
| **í´ë˜ìŠ¤** | helmet (18,966ê°œ), head (5,785ê°œ), person (751ê°œ) |

### Dataset 2: safety-Helmet-Reflective-Jacket
| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì´ë¯¸ì§€ ìˆ˜** | Train 7,350 / Valid 1,575 / Test 1,575 (ì´ 10,500ì¥) |
| **ë¼ë²¨ í˜•ì‹** | YOLO (TXT) âœ… |
| **ì´ë¯¸ì§€ í˜•ì‹** | JPG |
| **í´ë˜ìŠ¤** | 0: Safety-Helmet (10,868ê°œ), 1: Reflective-Jacket (8,210ê°œ) |

### í´ë˜ìŠ¤ ë§¤í•‘ ê³„íš
| í†µì¼ í´ë˜ìŠ¤ | Dataset 1 ì›ë³¸ | Dataset 2 ì›ë³¸ |
|-------------|----------------|----------------|
| 0: helmet | helmet | 0: Safety-Helmet |
| 1: vest | âŒ ì—†ìŒ | 1: Reflective-Jacket |
| - | head (ì œì™¸) | - |
| - | person (ì œì™¸) | - |

### ìµœì¢… ë°ì´í„°ì…‹ ì˜ˆìƒ
| í´ë˜ìŠ¤ | Dataset 1 | Dataset 2 | ì´ ê°œìˆ˜ |
|--------|-----------|-----------|---------|
| helmet | 18,966 | 10,868 | ~29,834 |
| vest | 0 | 8,210 | ~8,210 |

**ì´ ì´ë¯¸ì§€**: ~15,500ì¥ | **ì´ ê°ì²´**: ~38,044ê°œ

---

## ğŸ”§ ì „ì²˜ë¦¬ ì‹¤í–‰ (Phase 2-2)

### ì‹¤í–‰ ë°©ë²•

#### ì „ì²´ ì‹¤í–‰ (í•œ ë²ˆì—)
```bash
uv run python src/preprocess_all.py
```

#### ë‹¨ê³„ë³„ ì‹¤í–‰
```bash
# Step 1: Dataset 1 VOC â†’ YOLO ë³€í™˜
uv run python src/preprocess/step1_convert_voc_to_yolo.py

# Step 2: Dataset 2 í´ë˜ìŠ¤ ID í™•ì¸
uv run python src/preprocess/step2_verify_dataset2.py

# Step 3: ë°ì´í„°ì…‹ í†µí•©
uv run python src/preprocess/step3_merge_datasets.py

# Step 4: Train/Val/Test ë¶„í• 
uv run python src/preprocess/step4_split_dataset.py

# Step 5: YAML íŒŒì¼ ìƒì„±
uv run python src/preprocess/step5_generate_yaml.py

# Step 6: ë°ì´í„° ê²€ì¦
uv run python src/preprocess/step6_validate_dataset.py
```

---

### Step 1: Dataset 1 ë³€í™˜ (VOC â†’ YOLO) âœ… ì™„ë£Œ
```python
# í´ë˜ìŠ¤ ë§¤í•‘
dataset1_mapping = {
    'helmet': 0,   # â†’ helmet
    'head': -1,    # â†’ ì œì™¸
    'person': -1   # â†’ ì œì™¸
}
```

**ì‹¤í–‰ ê²°ê³¼:**
- ì…ë ¥: 5,000ê°œ XML íŒŒì¼
- ë³€í™˜ë¨: 4,581ê°œ (helmetì´ ìˆëŠ” ì´ë¯¸ì§€)
- ìŠ¤í‚µë¨: 419ê°œ (helmet ì—†ìŒ)
- ì¶œë ¥: `images/processed/dataset1/`

---

### Step 2: Dataset 2 í´ë˜ìŠ¤ ID í™•ì¸ âœ… ì™„ë£Œ
```python
# í´ë˜ìŠ¤ ë§¤í•‘ (ì´ë¯¸ YOLO í˜•ì‹)
dataset2_mapping = {
    0: 0,  # Safety-Helmet â†’ helmet
    1: 1   # Reflective-Jacket â†’ vest
}
```

**ì‹¤í–‰ ê²°ê³¼:**
- ì´ ì´ë¯¸ì§€: 10,500ê°œ (Train 7,350 / Valid 1,575 / Test 1,575)
- helmet: 20,191ê°œ
- vest: 16,049ê°œ
- ê²°ë¡ : ë³€í™˜ ë¶ˆí•„ìš”, ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥

---

### Step 3: ë°ì´í„° í†µí•© â³ ëŒ€ê¸°
- ë‘ ë°ì´í„°ì…‹ì„ `images/processed/merged/`ë¡œ ë³‘í•©
- íŒŒì¼ëª… ì¶©ëŒ ë°©ì§€ (prefix ì¶”ê°€: `ds1_`, `ds2_`)

---

### Step 4: Train/Val/Test ë¶„í•  â³ ëŒ€ê¸°
- Train/Val/Test ì¬ë¶„í•  (70/15/15)
- `images/train/`, `images/val/`, `images/test/`ì— ì €ì¥

---

### Step 5: ë°ì´í„°ì…‹ YAML ìƒì„± â³ ëŒ€ê¸°
```yaml
# configs/ppe_dataset.yaml
path: /path/to/SafetyVisionAI/images
train: train/images
val: val/images
test: test/images

nc: 2
names:
  0: helmet
  1: vest
```

---

### Step 6: ë°ì´í„° ê²€ì¦ â³ ëŒ€ê¸°
- ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­ í™•ì¸
- í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”
- ìƒ˜í”Œ ì´ë¯¸ì§€ ë°”ìš´ë”©ë°•ìŠ¤ ì‹œê°í™”

---

## âš¡ ì§‘ì¤‘ ê°œë°œ ì „ëµ (3ì£¼ ë‹¨ì¶• ê³„íš)

### í•µì‹¬ ê¸°ëŠ¥ ìš°ì„ ìˆœìœ„
1. **í•„ìˆ˜ ê¸°ëŠ¥**: PPE íƒì§€ (í—¬ë©§, ì•ˆì „ì¡°ë¼)
2. **ì¶”ê°€ ê¸°ëŠ¥**: ì›¹ ì¸í„°í˜ì´ìŠ¤ ëª¨ë‹ˆí„°ë§
3. **ì„ íƒ ê¸°ëŠ¥**: ê³ ê¸‰ ë¶„ì„, ë¦¬í¬íŠ¸ ìƒì„±

### ì‹œê°„ ë‹¨ì¶• ë°©ë²•
- **ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ í™œìš©**: ì²˜ìŒë¶€í„° í›ˆë ¨í•˜ì§€ ì•Šê³  Transfer Learning ì‚¬ìš©
- **ê³µê°œ ë°ì´í„°ì…‹ í™œìš©**: ìì²´ ë°ì´í„° ìˆ˜ì§‘ ëŒ€ì‹  ê²€ì¦ëœ ê³µê°œ ë°ì´í„°ì…‹ ì‚¬ìš©
- **ê²½ëŸ‰ ëª¨ë¸ ì„ íƒ**: MobileNet ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥¸ ê°œë°œê³¼ ì¶”ë¡ 
- **ìµœì†Œ ê¸°ëŠ¥ êµ¬í˜„**: í•µì‹¬ ê¸°ëŠ¥ì— ì§‘ì¤‘, ë¶€ê°€ ê¸°ëŠ¥ ìµœì†Œí™”

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

### ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹
- **Framework**: TensorFlow 2.13.0 âœ…
- **ëª¨ë¸**: MobileNet-SSD, EfficientDet (ê²½ëŸ‰í™” ìš°ì„ )
- **ì „ì²˜ë¦¬**: OpenCV, NumPy
- **ì‹œê°í™”**: Matplotlib

### ê°œë°œ í™˜ê²½
- **ì–¸ì–´**: Python 3.11 âœ…
- **ê°€ìƒí™˜ê²½**: uv âœ…
- **ë²„ì „ê´€ë¦¬**: Git
- **ë…¸íŠ¸ë¶**: Jupyter âœ…

### ë°°í¬ ë° ì„œë¹™
- **ì›¹ ì¸í„°í˜ì´ìŠ¤**: Streamlit (ë¹ ë¥¸ êµ¬í˜„)
- **ì¶”ë¡  ìµœì í™”**: TensorFlow Lite (ëª¨ë°”ì¼ ìµœì í™”)
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: OpenCV VideoCapture

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
SafetyVisionAI/
â”œâ”€â”€ materials/              # í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì„œ ë° ìë£Œ
â”‚   â”œâ”€â”€ papers/            # ì—°êµ¬ë…¼ë¬¸
â”‚   â”œâ”€â”€ patents/           # íŠ¹í—ˆ ìë£Œ
â”‚   â””â”€â”€ company/           # íšŒì‚¬ ìë£Œ
â”œâ”€â”€ data/                   # ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ raw/               # ì›ë³¸ ë°ì´í„° (ë‹¤ìš´ë¡œë“œí•œ ê·¸ëŒ€ë¡œ)
â”‚   â”œâ”€â”€ processed/         # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”œâ”€â”€ train/             # í›ˆë ¨ìš© ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ images/       # ì´ë¯¸ì§€
â”‚   â”‚   â””â”€â”€ labels/       # ë¼ë²¨ (YOLO/COCO/VOC í˜•ì‹)
â”‚   â”œâ”€â”€ val/               # ê²€ì¦ìš© ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ labels/
â”‚   â””â”€â”€ test/              # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°
â”‚       â”œâ”€â”€ images/
â”‚       â””â”€â”€ labels/
â”œâ”€â”€ models/                # í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼
â”‚   â”œâ”€â”€ best_model.pt      # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
â”‚   â”œâ”€â”€ last_model.pt      # ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸
â”‚   â””â”€â”€ checkpoints/       # ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ë“¤
â”œâ”€â”€ src/                   # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ preprocess.py      # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ dataloader.py      # ë°ì´í„° ë¡œë”
â”‚   â”œâ”€â”€ train.py           # ëª¨ë¸ í›ˆë ¨
â”‚   â”œâ”€â”€ evaluate.py        # ëª¨ë¸ í‰ê°€
â”‚   â”œâ”€â”€ inference.py       # ì¶”ë¡ /ì˜ˆì¸¡
â”‚   â””â”€â”€ utils.py           # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ notebooks/             # Jupyter ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ data_analysis.ipynb    # ë°ì´í„° ë¶„ì„
â”‚   â”œâ”€â”€ model_training.ipynb   # ëª¨ë¸ í›ˆë ¨ ì‹¤í—˜
â”‚   â””â”€â”€ visualization.ipynb    # ê²°ê³¼ ì‹œê°í™”
â”œâ”€â”€ configs/               # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ train_config.yaml  # í›ˆë ¨ ì„¤ì •
â”‚   â””â”€â”€ model_config.yaml  # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ pyproject.toml         # Python ì˜ì¡´ì„± (uv ì‚¬ìš©)
â”œâ”€â”€ uv.lock               # ì˜ì¡´ì„± ë½íŒŒì¼
â”œâ”€â”€ main.py               # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â”œâ”€â”€ CLAUDE.md             # í”„ë¡œì íŠ¸ ì§€ì¹¨ì„œ
â””â”€â”€ README.md             # í”„ë¡œì íŠ¸ ì„¤ëª…
```

## ğŸ¯ ì£¼ìš” ë§ˆì¼ìŠ¤í†¤ (12ì›” 7ì¼ ë§ˆê°)

- **11/24 (Week 1)**: ë°ì´í„°ì…‹ í™•ë³´ ë° ê¸°ë³¸ ëª¨ë¸ êµ¬í˜„ ì™„ë£Œ
- **12/1 (Week 2)**: ëª¨ë¸ í›ˆë ¨ ë° ì¶”ë¡  ì‹œìŠ¤í…œ ì™„ë£Œ
- **12/7 (Week 3)**: ìµœì¢… ì‹œìŠ¤í…œ ì™„ì„± ë° ë°œí‘œ ì¤€ë¹„ ì™„ë£Œ

## â° ì¼ì • ê´€ë¦¬ ì „ëµ

### ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘ ë°©ì•ˆ
1. **ë°ì´í„°ì…‹ í™•ë³´ ì§€ì—°** â†’ ë‹¤ì¤‘ ì†ŒìŠ¤ì—ì„œ ë™ì‹œ ë‹¤ìš´ë¡œë“œ
2. **ëª¨ë¸ í›ˆë ¨ ì‹œê°„ ë¶€ì¡±** â†’ í´ë¼ìš°ë“œ GPU í™œìš© ê²€í† 
3. **í†µí•© í…ŒìŠ¤íŠ¸ ì‹œê°„ ë¶€ì¡±** â†’ ì£¼ê°„ë³„ ì ê²€ ê°•í™”

### íš¨ìœ¨ì„± ê·¹ëŒ€í™” ë°©ë²•
- **ë³‘ë ¬ ì‘ì—…**: ë°ì´í„° ì „ì²˜ë¦¬ì™€ ëª¨ë¸ ì—°êµ¬ ë™ì‹œ ì§„í–‰
- **ì¼ì¼ ì²´í¬í¬ì¸íŠ¸**: ë§¤ì¼ ì§„í–‰ìƒí™© ì ê²€ ë° ì¡°ì •
- **MVP ì ‘ê·¼ë²•**: ìµœì†Œ ê¸°ëŠ¥ ì œí’ˆ ë¨¼ì € ì™„ì„± í›„ ê°œì„ 

## ğŸ”„ ê°œë°œ ì›Œí¬í”Œë¡œìš° (ë°ì´í„°ì…‹ ìˆ˜ì§‘ í›„)

### 1. ë°ì´í„° ì „ì²˜ë¦¬ (Preprocessing)
```bash
uv run python src/preprocess.py --input data/raw/ --output data/processed/
```
- **ë°ì´í„° ê²€ì¦**: ì´ë¯¸ì§€ì™€ ë¼ë²¨ íŒŒì¼ ë§¤ì¹­ í™•ì¸
- **ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•**: ëª¨ë¸ ì…ë ¥ í¬ê¸° ë§ì¶¤ (ì˜ˆ: 640x640)
- **ì •ê·œí™”**: í”½ì…€ ê°’ 0-1 ë˜ëŠ” -1~1ë¡œ ë³€í™˜
- **ë¼ë²¨ í¬ë§· ë³€í™˜**: COCO â†’ YOLO, Pascal VOC ë“±
- **ë°ì´í„° ì •ì œ**: ì†ìƒëœ íŒŒì¼, ì˜ëª»ëœ ë¼ë²¨ ì œê±°

### 2. ë°ì´í„° ë¶„í•  (Train/Validation/Test Split)
```
ë°ì´í„°ì…‹ ë¶„í•  ë¹„ìœ¨:
â”œâ”€â”€ train (70-80%): ëª¨ë¸ í•™ìŠµìš©
â”œâ”€â”€ val (10-15%): í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, ì¡°ê¸° ì¢…ë£Œ
â””â”€â”€ test (10-15%): ìµœì¢… ì„±ëŠ¥ í‰ê°€
```

### 3. ë°ì´í„° ì¦ê°• (Data Augmentation)
í›ˆë ¨ ë°ì´í„° ë‹¤ì–‘ì„± ì¦ê°€:
- íšŒì „ (Rotation)
- ë°˜ì „ (Horizontal/Vertical Flip)
- ë°ê¸°/ëŒ€ë¹„ ì¡°ì ˆ (Brightness/Contrast)
- ë…¸ì´ì¦ˆ ì¶”ê°€ (Gaussian Noise)
- Mosaic, Mixup
- Random Crop/Scale

### 4. ëª¨ë¸ ì„ íƒ ë° ì„¤ì •
```yaml
# configs/train_config.yaml
model: yolov8n        # yolov5, yolov8, faster-rcnn ë“±
num_classes: 7        # PPE í´ë˜ìŠ¤ ìˆ˜
input_size: 640       # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
batch_size: 16
epochs: 100
learning_rate: 0.001
```

**ëª¨ë¸ ì˜µì…˜:**
- **YOLO (v5, v8, v10)**: ë¹ ë¥¸ ì‹¤ì‹œê°„ íƒì§€ (ê¶Œì¥)
- **Faster R-CNN**: ë†’ì€ ì •í™•ë„, ëŠë¦° ì†ë„
- **EfficientDet**: ì •í™•ë„-ì†ë„ ê· í˜•
- **DETR**: Transformer ê¸°ë°˜

### 5. ëª¨ë¸ í›ˆë ¨ (Training)
```bash
uv run python src/train.py --config configs/train_config.yaml
```
- **ì „ì´ í•™ìŠµ** (Transfer Learning): COCO ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš©
- **ì†ì‹¤ í•¨ìˆ˜**: Classification Loss + Localization Loss
- **ì˜µí‹°ë§ˆì´ì €**: Adam, SGD, AdamW ë“±
- **í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§**: CosineAnnealing, StepLR
- **ì¡°ê¸° ì¢…ë£Œ** (Early Stopping): ê³¼ì í•© ë°©ì§€
- **ì²´í¬í¬ì¸íŠ¸ ì €ì¥**: ìµœê³ /ìµœì‹  ëª¨ë¸ ì €ì¥

### 6. ëª¨ë¸ í‰ê°€ (Evaluation)
```bash
uv run python src/evaluate.py --model models/best_model.pt --data data/test/
```
**í‰ê°€ ì§€í‘œ:**
- **mAP** (mean Average Precision): @0.5, @0.75, @0.5:0.95
- **Precision**: ì •ë°€ë„ (ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨)
- **Recall**: ì¬í˜„ìœ¨ (ë†“ì¹˜ì§€ ì•Šì€ ë¹„ìœ¨)
- **F1-Score**: Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· 
- **FPS** (Frames Per Second): ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥

### 7. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
ìµœì í™”í•  íŒŒë¼ë¯¸í„°:
```yaml
learning_rate: [0.001, 0.0001, 0.00001]
batch_size: [8, 16, 32]
optimizer: [adam, sgd, adamw]
weight_decay: [0.0005, 0.001]
augmentation_strength: [weak, medium, strong]
```

### 8. ëª¨ë¸ ì¶”ë¡  ë° í…ŒìŠ¤íŠ¸
```bash
# ì´ë¯¸ì§€ ì¶”ë¡ 
uv run python src/inference.py --model models/best_model.pt --input test_image.jpg

# ë¹„ë””ì˜¤ ì¶”ë¡ 
uv run python src/inference.py --model models/best_model.pt --input video.mp4

# ì›¹ìº  ì‹¤ì‹œê°„ ì¶”ë¡ 
uv run python src/inference.py --model models/best_model.pt --source webcam
```

### 9. ëª¨ë¸ ë°°í¬ ì¤€ë¹„
- **ëª¨ë¸ ê²½ëŸ‰í™”**: Pruning, Quantization (INT8)
- **í¬ë§· ë³€í™˜**: ONNX, TensorRT, TensorFlow Lite
- **API ì„œë²„**: Flask, FastAPIë¡œ REST API êµ¬ì¶•
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: CCTV, ì›¹ìº  ì—°ë™

## ğŸ“‹ ë¼ë²¨ë§ ë°ì´í„° í˜•ì‹

### YOLO í˜•ì‹ (.txt)
```
# class_id x_center y_center width height (ëª¨ë‘ ì •ê·œí™”ëœ 0-1 ê°’)
0 0.5 0.5 0.3 0.4
1 0.7 0.3 0.2 0.2
```

### COCO í˜•ì‹ (.json)
```json
{
  "images": [{"id": 1, "file_name": "image001.jpg", "width": 1920, "height": 1080}],
  "annotations": [
    {
      "id": 1,
      "image_id": 1,
      "category_id": 1,
      "bbox": [100, 150, 200, 250],
      "area": 50000,
      "iscrowd": 0
    }
  ],
  "categories": [{"id": 1, "name": "helmet"}]
}
```

### Pascal VOC í˜•ì‹ (.xml)
```xml
<annotation>
  <object>
    <name>helmet</name>
    <bndbox>
      <xmin>100</xmin>
      <ymin>150</ymin>
      <xmax>300</xmax>
      <ymax>400</ymax>
    </bndbox>
  </object>
</annotation>
```

## ğŸ¨ PPE íƒì§€ í´ë˜ìŠ¤ ì •ì˜

```yaml
classes:
  0: helmet      # í—¬ë©§ ì°©ìš©
  1: vest        # ì•ˆì „ì¡°ë¼ ì°©ìš©
  2: head        # í—¬ë©§ ë¯¸ì°©ìš© (ë¨¸ë¦¬ë§Œ ë³´ì„)
```

**ë°ì´í„°ì…‹ ì¶œì²˜:**
- Hard Hat Detection (Kaggle): helmet, head í´ë˜ìŠ¤
- Safety Helmet and Reflective Jacket (Kaggle): helmet, vest í´ë˜ìŠ¤

## ğŸ› ï¸ ë¼ë²¨ë§ ë„êµ¬ ì¶”ì²œ

ì§ì ‘ ë¼ë²¨ë§ì´ í•„ìš”í•œ ê²½ìš°:
- **LabelImg**: YOLO, Pascal VOC í˜•ì‹ ì§€ì›
- **CVAT**: ì›¹ ê¸°ë°˜, í˜‘ì—… ê°€ëŠ¥, ë‹¤ì–‘í•œ í˜•ì‹
- **Roboflow**: ì˜¨ë¼ì¸, ìë™ í¬ë§· ë³€í™˜, ë°ì´í„° ì¦ê°•
- **Labelbox**: ìƒìš©, ê³ ê¸‰ ê¸°ëŠ¥
- **VGG Image Annotator (VIA)**: ì˜¤í”ˆì†ŒìŠ¤, ê²½ëŸ‰

## ğŸ“Š ì„±ê³µ ì§€í‘œ

1. **ì •í™•ë„**: mAP@0.5 > 85%
2. **ì‹¤ì‹œê°„ì„±**: 30 FPS ì´ìƒ (ì›¹ìº  ì²˜ë¦¬)
3. **ì•ˆì •ì„±**: 24ì‹œê°„ ì—°ì† ìš´ì˜ ê°€ëŠ¥
4. **ì‚¬ìš©ì„±**: ì§ê´€ì ì¸ UI/UX

## ğŸ”— ì°¸ê³  ìë£Œ

- [YOLO ê³µì‹ ë¬¸ì„œ](https://docs.ultralytics.com/)
- [PyTorch ê°ì²´ íƒì§€ íŠœí† ë¦¬ì–¼](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)
- [ì‚°ì—…ì•ˆì „ PPE ë°ì´í„°ì…‹](https://github.com/akanametov/ppedetection)
- í”„ë¡œì íŠ¸ ê´€ë ¨ ë…¼ë¬¸: `ë”¥ ëŸ¬ë‹ ê¸°ë°˜ ì‘ì—…ì ê°œì¸ë³´í˜¸êµ¬ ì°©ìš© ë° ì–¼êµ´ ì‹ ì› í™•ì¸ ì‹œìŠ¤í…œì— ê´€í•œ ì—°êµ¬`

## ğŸ“ íŒ€ ì •ë³´

- **íŒ€ëª…**: 3ì¡°
- **í”„ë¡œì íŠ¸ëª…**: TFGuard
- **ëª©í‘œ**: ì‚°ì—…í˜„ì¥ ì•ˆì „ì‚¬ê³  ì˜ˆë°©ì„ ìœ„í•œ AI ì‹œìŠ¤í…œ ê°œë°œ