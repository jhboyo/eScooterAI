{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8 PPE Detection ëª¨ë¸ í›ˆë ¨ (3 Class)\n",
    "\n",
    "## ê°œìš”\n",
    "ì´ ë…¸íŠ¸ë¶ì€ YOLOv8 ëª¨ë¸ì„ PPE ë°ì´í„°ì…‹(3 class)ìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ë©”ì¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.\n",
    "Transfer Learningì„ í™œìš©í•˜ì—¬ COCO ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "## íƒì§€ í´ë˜ìŠ¤\n",
    "- **Class 0**: helmet (í—¬ë©§ ì°©ìš©) âœ…\n",
    "- **Class 1**: head (í—¬ë©§ ë¯¸ì°©ìš©) âš ï¸\n",
    "- **Class 2**: vest (ì•ˆì „ì¡°ë¼ ì°©ìš©) âœ…\n",
    "\n",
    "## ì‹¤í–‰ ê³¼ì •\n",
    "1. YOLOv8 ëª¨ë¸ ë¡œë“œ (yolov8n.pt - Nano ë²„ì „)\n",
    "2. configs/train_config.yamlì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œë“œ\n",
    "3. configs/ppe_dataset.yamlì—ì„œ ë°ì´í„°ì…‹ ì •ë³´ ë¡œë“œ\n",
    "4. í›ˆë ¨ ì‹¤í–‰ ë° ëª¨ë¸ ì €ì¥\n",
    "5. í›ˆë ¨ ê²°ê³¼ ë° í†µê³„ ì¶œë ¥\n",
    "\n",
    "## ì¶œë ¥ íŒŒì¼\n",
    "í›ˆë ¨ ì™„ë£Œ í›„ models/ppe_detection/ í´ë”ì— ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤:\n",
    "- `weights/best.pt`: ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "- `weights/last.pt`: ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸\n",
    "- `results.csv`: ì—í¬í¬ë³„ í›ˆë ¨ í†µê³„\n",
    "- `confusion_matrix.png`: í˜¼ë™ í–‰ë ¬\n",
    "- `PR_curve.png`: Precision-Recall ê³¡ì„ \n",
    "- `results.png`: í›ˆë ¨ ê²°ê³¼ ê·¸ë˜í”„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_device():\n",
    "    \"\"\"\n",
    "    ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ í™•ì¸\n",
    "    \n",
    "    Returns:\n",
    "        str: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cuda', 'mps', 'cpu')\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"ğŸ® CUDA GPU ì‚¬ìš© ê°€ëŠ¥: {device_name}\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "        print(\"ğŸ Apple Silicon MPS ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"ğŸ’» GPU ì‚¬ìš© ë¶ˆê°€, CPUë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"\n",
    "    í›ˆë ¨ ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "    \n",
    "    Args:\n",
    "        config_path: train_config.yaml íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        dict: ì„¤ì • ë”•ì…”ë„ˆë¦¬\n",
    "    \"\"\"\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "print(\"âœ… í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (ë…¸íŠ¸ë¶ ìœ„ì¹˜ ê¸°ì¤€)\n",
    "# notebooks/training/train_yolov8.ipynb -> í”„ë¡œì íŠ¸ ë£¨íŠ¸\n",
    "project_root = Path.cwd().parent.parent\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "env_path = project_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âš ï¸ .env íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "# ê²½ë¡œ í™•ì¸\n",
    "print(f\"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}\")\n",
    "print(f\"ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. í›ˆë ¨ ì„¤ì •\n",
    "\n",
    "### 4.1 ì„¤ì • íŒŒì¼ ê²½ë¡œ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì • íŒŒì¼ ê²½ë¡œ\n",
    "config_path = project_root / 'configs' / 'train_config.yaml'\n",
    "data_yaml = project_root / 'configs' / 'ppe_dataset.yaml'\n",
    "\n",
    "print(f\"ğŸ“„ ì„¤ì • íŒŒì¼: {config_path}\")\n",
    "print(f\"ğŸ“„ ë°ì´í„°ì…‹ íŒŒì¼: {data_yaml}\")\n",
    "\n",
    "# íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "assert config_path.exists(), f\"âŒ ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {config_path}\"\n",
    "assert data_yaml.exists(), f\"âŒ ë°ì´í„°ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_yaml}\"\n",
    "print(\"âœ… ëª¨ë“  ì„¤ì • íŒŒì¼ í™•ì¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (ìˆ˜ì • ê°€ëŠ¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸ”§ ì´ ê°’ë“¤ì„ ìˆ˜ì •í•˜ì—¬ í›ˆë ¨ ì„¤ì • ë³€ê²½\n",
    "# ========================================\n",
    "\n",
    "# í›ˆë ¨ ê¸°ë³¸ ì„¤ì •\n",
    "EPOCHS = None          # Noneì´ë©´ config íŒŒì¼ ê°’ ì‚¬ìš© (ê¸°ë³¸: 100)\n",
    "BATCH_SIZE = None      # Noneì´ë©´ config íŒŒì¼ ê°’ ì‚¬ìš© (ê¸°ë³¸: 128)\n",
    "DEVICE = None          # Noneì´ë©´ ìë™ ê°ì§€ (cuda, mps, cpu)\n",
    "\n",
    "# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ì„¤ì • (MacBook ë“±)\n",
    "# EPOCHS = 1\n",
    "# BATCH_SIZE = 16\n",
    "# DEVICE = 'mps'\n",
    "\n",
    "# A100 ë³¸ í›ˆë ¨ìš© ì„¤ì •\n",
    "# EPOCHS = 100\n",
    "# BATCH_SIZE = 128\n",
    "# DEVICE = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ì„¤ì • íŒŒì¼ ë¡œë“œ ë° ì„¤ì •ê°’ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"YOLOv8 PPE Detection ëª¨ë¸ í›ˆë ¨ (3 Class)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "print(\"ğŸ“‹ ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘...\")\n",
    "config = load_config(config_path)\n",
    "\n",
    "# ì„¤ì •ê°’ ì¶”ì¶œ\n",
    "model_name = config['model']['name']\n",
    "epochs = EPOCHS if EPOCHS is not None else config['train']['epochs']\n",
    "batch_size = BATCH_SIZE if BATCH_SIZE is not None else config['train']['batch_size']\n",
    "img_size = config['train']['img_size']\n",
    "patience = config['train']['patience']\n",
    "workers = config['train'].get('workers', 8)\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "if DEVICE:\n",
    "    device = DEVICE\n",
    "elif config.get('device'):\n",
    "    device = config['device']\n",
    "else:\n",
    "    device = check_device()\n",
    "\n",
    "# Optimizer ì„¤ì •\n",
    "optimizer = config['train']['optimizer']\n",
    "lr0 = config['train']['lr0']\n",
    "lrf = config['train']['lrf']\n",
    "momentum = config['train']['momentum']\n",
    "weight_decay = config['train']['weight_decay']\n",
    "warmup_epochs = config['train']['warmup_epochs']\n",
    "\n",
    "# ì¶œë ¥ ì„¤ì •\n",
    "save_dir = config['output']['save_dir']\n",
    "name = config['output']['name']\n",
    "exist_ok = config['output']['exist_ok']\n",
    "\n",
    "# ì¦ê°• ì„¤ì •\n",
    "augment = config['augment']\n",
    "\n",
    "# ì„¤ì • ì¶œë ¥\n",
    "print(f\"   âœ… ëª¨ë¸: {model_name}\")\n",
    "print(f\"   âœ… ë°ì´í„°ì…‹: {data_yaml}\")\n",
    "print(f\"   âœ… Epochs: {epochs}\")\n",
    "print(f\"   âœ… Batch Size: {batch_size}\")\n",
    "print(f\"   âœ… Image Size: {img_size}\")\n",
    "print(f\"   âœ… Device: {device}\")\n",
    "print(f\"   âœ… Optimizer: {optimizer}\")\n",
    "print(f\"   âœ… Learning Rate: {lr0} -> {lrf}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. YOLOv8 ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– YOLOv8 ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ë¡œë“œ (Transfer Learning)\n",
    "# yolov8n.pt: COCO ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ Nano ë²„ì „\n",
    "model = YOLO(f\"{model_name}.pt\")\n",
    "\n",
    "print(f\"   âœ… {model_name}.pt ë¡œë“œ ì™„ë£Œ\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰\n",
    "\n",
    "### âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "- í›ˆë ¨ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤ (A100 GPU 100 epochs: ì•½ 54ë¶„)\n",
    "- ì¤‘ê°„ì— ì¤‘ë‹¨í•˜ë©´ `weights/last.pt`ì—ì„œ ì¬ê°œ ê°€ëŠ¥\n",
    "- í›ˆë ¨ ì¤‘ ì‹¤ì‹œê°„ ë¡œê·¸ê°€ ì¶œë ¥ë©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ í›ˆë ¨ ì‹œì‘...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# í›ˆë ¨ ì‹¤í–‰\n",
    "results = model.train(\n",
    "    # ë°ì´í„°ì…‹ ì„¤ì •\n",
    "    data=str(data_yaml),\n",
    "    \n",
    "    # ê¸°ë³¸ í›ˆë ¨ ì„¤ì •\n",
    "    epochs=epochs,\n",
    "    batch=batch_size,\n",
    "    imgsz=img_size,\n",
    "    patience=patience,\n",
    "    workers=workers,\n",
    "    \n",
    "    # Optimizer ì„¤ì •\n",
    "    optimizer=optimizer,\n",
    "    lr0=lr0,\n",
    "    lrf=lrf,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay,\n",
    "    warmup_epochs=warmup_epochs,\n",
    "    warmup_momentum=config['train']['warmup_momentum'],\n",
    "    warmup_bias_lr=config['train']['warmup_bias_lr'],\n",
    "    \n",
    "    # ì¦ê°• ì„¤ì •\n",
    "    hsv_h=augment['hsv_h'],\n",
    "    hsv_s=augment['hsv_s'],\n",
    "    hsv_v=augment['hsv_v'],\n",
    "    degrees=augment['degrees'],\n",
    "    translate=augment['translate'],\n",
    "    scale=augment['scale'],\n",
    "    shear=augment['shear'],\n",
    "    flipud=augment['flipud'],\n",
    "    fliplr=augment['fliplr'],\n",
    "    mosaic=augment['mosaic'],\n",
    "    mixup=augment['mixup'],\n",
    "    \n",
    "    # ì¶œë ¥ ì„¤ì •\n",
    "    project=save_dir,\n",
    "    name=name,\n",
    "    exist_ok=exist_ok,\n",
    "    \n",
    "    # ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "    device=device,\n",
    "    \n",
    "    # ë¡œê·¸ ì„¤ì •\n",
    "    verbose=config['verbose'],\n",
    "    save_period=config['save_period'],\n",
    "    \n",
    "    # ê¸°íƒ€ ì„¤ì •\n",
    "    save=True,          # ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "    plots=True,         # í›ˆë ¨ ê·¸ë˜í”„ ì €ì¥\n",
    "    val=True,           # í›ˆë ¨ ì¤‘ ê²€ì¦ ìˆ˜í–‰\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ‰ í›ˆë ¨ ì™„ë£Œ!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. í›ˆë ¨ ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ íŒŒì¼ ê²½ë¡œ\n",
    "output_path = Path(save_dir) / name\n",
    "weights_path = output_path / 'weights'\n",
    "\n",
    "print(\"\\nğŸ“‚ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜:\")\n",
    "print(f\"   ğŸ“ {output_path}\")\n",
    "print()\n",
    "print(\"ğŸ“¦ ìƒì„±ëœ íŒŒì¼:\")\n",
    "print(f\"   ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {weights_path / 'best.pt'}\")\n",
    "print(f\"   ğŸ’¾ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸: {weights_path / 'last.pt'}\")\n",
    "print(f\"   ğŸ“Š í›ˆë ¨ í†µê³„: {output_path / 'results.csv'}\")\n",
    "print(f\"   ğŸ”¢ í˜¼ë™ í–‰ë ¬: {output_path / 'confusion_matrix.png'}\")\n",
    "print(f\"   ğŸ“ˆ PR ê³¡ì„ : {output_path / 'PR_curve.png'}\")\n",
    "print(f\"   ğŸ“‰ í›ˆë ¨ ê·¸ë˜í”„: {output_path / 'results.png'}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 ìµœê³  ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœê³  ì„±ëŠ¥ ì¶œë ¥\n",
    "if hasattr(results, 'results_dict'):\n",
    "    print(\"\\nğŸ† ìµœê³  ì„±ëŠ¥ í†µê³„:\")\n",
    "    metrics = results.results_dict\n",
    "    \n",
    "    if 'metrics/mAP50(B)' in metrics:\n",
    "        print(f\"   ğŸ“Š mAP@0.5: {metrics['metrics/mAP50(B)']:.4f} ({metrics['metrics/mAP50(B)']*100:.2f}%)\")\n",
    "    \n",
    "    if 'metrics/mAP50-95(B)' in metrics:\n",
    "        print(f\"   ğŸ“Š mAP@0.5:0.95: {metrics['metrics/mAP50-95(B)']:.4f} ({metrics['metrics/mAP50-95(B)']*100:.2f}%)\")\n",
    "    \n",
    "    if 'metrics/precision(B)' in metrics:\n",
    "        print(f\"   ğŸ¯ Precision: {metrics['metrics/precision(B)']:.4f} ({metrics['metrics/precision(B)']*100:.2f}%)\")\n",
    "    \n",
    "    if 'metrics/recall(B)' in metrics:\n",
    "        print(f\"   ğŸ” Recall: {metrics['metrics/recall(B)']:.4f} ({metrics['metrics/recall(B)']*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"âš ï¸ ì„±ëŠ¥ ì§€í‘œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 í›ˆë ¨ ê·¸ë˜í”„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# í›ˆë ¨ ê²°ê³¼ ê·¸ë˜í”„ í‘œì‹œ\n",
    "results_img = output_path / 'results.png'\n",
    "if results_img.exists():\n",
    "    print(\"ğŸ“Š í›ˆë ¨ ê²°ê³¼ ê·¸ë˜í”„:\")\n",
    "    display(Image(filename=str(results_img)))\n",
    "else:\n",
    "    print(\"âš ï¸ í›ˆë ¨ ê²°ê³¼ ê·¸ë˜í”„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜¼ë™ í–‰ë ¬ í‘œì‹œ\n",
    "confusion_matrix_img = output_path / 'confusion_matrix.png'\n",
    "if confusion_matrix_img.exists():\n",
    "    print(\"ğŸ”¢ í˜¼ë™ í–‰ë ¬:\")\n",
    "    display(Image(filename=str(confusion_matrix_img)))\n",
    "else:\n",
    "    print(\"âš ï¸ í˜¼ë™ í–‰ë ¬ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Precision-Recall ê³¡ì„  ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR ê³¡ì„  í‘œì‹œ\n",
    "pr_curve_img = output_path / 'PR_curve.png'\n",
    "if pr_curve_img.exists():\n",
    "    print(\"ğŸ“ˆ Precision-Recall ê³¡ì„ :\")\n",
    "    display(Image(filename=str(pr_curve_img)))\n",
    "else:\n",
    "    print(\"âš ï¸ PR ê³¡ì„ ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### 8.1 ëª¨ë¸ í‰ê°€\n",
    "```bash\n",
    "uv run python src/4_test/evaluate.py\n",
    "```\n",
    "\n",
    "### 8.2 ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
    "```bash\n",
    "uv run python src/3_inference/inference.py --source test_image.jpg\n",
    "```\n",
    "\n",
    "### 8.3 ëª¨ë¸ íŒŒì¼ ê²½ë¡œ\n",
    "- ìµœê³  ì„±ëŠ¥ ëª¨ë¸: `models/ppe_detection/weights/best.pt`\n",
    "- ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸: `models/ppe_detection/weights/last.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\në‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"   1ï¸âƒ£ ëª¨ë¸ í‰ê°€: uv run python src/4_test/evaluate.py\")\n",
    "print(\"   2ï¸âƒ£ ì¶”ë¡  í…ŒìŠ¤íŠ¸: uv run python src/3_inference/inference.py --source test_image.jpg\")\n",
    "print(\"   3ï¸âƒ£ ê²°ê³¼ ë¶„ì„: training_report.md ì°¸ê³ \")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
